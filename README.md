# DSP_final_project
# Multimodal Biosignals Space-Invader Game

An interactive **Space-Invaderâ€“style game** controlled by multiple human biosignals and perceptual modalities, including **ECG, EMG, speech (MFCC), and computer visionâ€“based hand tracking**. This project integrates classical DSP techniques taught in class with independently designed signal processing and real-time interaction modules.

---

## ğŸ® Project Overview

This project transforms physiological and behavioral signals into intuitive game controls:

* **Computer Vision (CV)** â€“ Continuous left/right spaceship movement using hand tracking
* **EMG (Electromyography)** â€“ Voluntary muscle activation for firing actions
* **Speech Recognition (MFCC + CNN)** â€“ Discrete voice commands (e.g., *shoot*, *bomb*)
* **ECG (Electrocardiography)** â€“ Heart-rateâ€“driven adaptive game difficulty

The goal is not only functional correctness, but also **robust real-time performance**, **low latency**, and **engaging biofeedback-driven interaction**.

---

## ğŸ§  System Architecture

The system follows a modular real-time architecture:

```
Sensors / Inputs
 â”œâ”€ ECG + EMG  â”€â”€â–º SensorThread (DSP processing)
 â”œâ”€ Microphone â”€â”€â–º MFCC + CNN (VoiceControl)
 â”œâ”€ Webcam     â”€â”€â–º Mediapipe Hand Tracking
 â””â”€ Keyboard   â”€â”€â–º Fallback Control

            â–¼
      Control Signals
 (movement, firing, commands, difficulty)
            â–¼
        Pygame Engine
 (game logic, rendering, collision)
```

All modules operate concurrently and communicate with a central **Pygame-based game loop** running at 60 FPS.

---

## ğŸ›  Signal Processing Pipelines

### ECG (Course Content)

* Instrumentation amplifier + analog band-limiting (conceptual front-end)
* Digital band-pass filtering (5â€“40 Hz)
* Squaring + moving-window integration
* Adaptive thresholding for R-peak detection
* BPM estimation

**Game mapping:** Higher BPM â†’ faster enemy movement and descent (biofeedback loop)

---

### EMG (Independent Work)

* Band-pass filtering (20â€“150 Hz)
* Full-wave rectification
* Envelope extraction via low-pass smoothing
* Rolling mean normalization
* Adaptive threshold + refractory logic

**Design choice:** No 60 Hz notch filter, preserving broadband muscle activation energy and temporal fidelity.

**Game mapping:** Muscle contraction â†’ firing trigger

---

### Speech Recognition (Course Content + Extension)

* Short-time framing + Hamming window
* STFT â†’ Mel filter banks â†’ MFCC extraction
* CNN-based command classification (*shoot*, *bomb*)
* Sliding window + energy gating for real-time robustness

---

### Computer Vision (Independent Work)

* Mediapipe hand landmark detection
* Palm center estimation
* Screen-coordinate mapping
* Exponential moving average (EMA) smoothing

**Game mapping:** Horizontal spaceship movement

---

## ğŸ“ Project Structure

```
â”œâ”€ main.py                # Main game loop (Pygame)
â”œâ”€ sensor_thread.py       # ECG & EMG acquisition + processing
â”œâ”€ emg_processor.py       # EMG DSP pipeline 
â”œâ”€ ecg_processor.py       # ECG DSP pipeline 
â”œâ”€ voice_control.py       # MFCC + CNN speech recognition
â”œâ”€ mfcc_train.py          # using MFCC + CNN to train model
â”œâ”€ README.md
```

---

## â–¶ï¸ How to Run

### Requirements

* Python 3.8+
* numpy, scipy
* pygame
* opencv-python
* mediapipe
* torch, torchaudio

Install dependencies:

```bash
pip install numpy scipy pygame opencv-python mediapipe torch torchaudio
```

### Run the Game

```bash
python main.py
```

If sensors or camera are unavailable, the system automatically falls back to keyboard control.

---

## ğŸ¯ Controls Summary

| Modality  | Function                  |
| --------- | ------------------------- |
| Hand (CV) | Move spaceship left/right |
| EMG       | Fire bullet               |
| Voice     | Shoot / Bomb              |
| ECG       | Modulate difficulty       |
| Keyboard  | Backup control            |

---

## âœ¨ Key Contributions

* Designed an **adaptive EMG processing pipeline** robust to user variability
* Integrated **real-time multimodal biosignals** into a game engine
* Demonstrated **biofeedback-driven difficulty modulation** using ECG
* Combined DSP, machine learning, and HCI principles in a single system

---

## ğŸ“Œ Notes

* ECG and MFCC pipelines follow DSP methods taught in class
* EMG processing, CV control, multimodal interaction logic, and system integration are independently implemented
* The project emphasizes **engineering trade-offs** over purely offline accuracy

---

## ğŸ‘¤ Author

Chih-Ling Kuo
Department of Electrical Engineering

---

*This project demonstrates how classical DSP techniques can be transformed into playful, real-time humanâ€“machine interaction systems.*
